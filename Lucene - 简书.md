一、Lucene概述

1、Lucene简介
Lucene是apache下的一个开源的全文检索引擎工具包。

2、 全文检索（Full-text Search）

定义

全文检索就是先“分词”创建索引，再执行搜索的过程。

分词：就是将一段文字分成一个个单词
全文检索就将一段文字分成一个个单词去查询数据！！！

应用场景

（1）搜索引擎（了解）
搜索引擎是一个基于全文检索、能独立运行、提供搜索服务的软件系统。

（2）电商站内搜索（重点）
思考：电商网站内，我们都是通过输入关键词来搜索商品的。如果我们根据关键词，直接查询数据库，会有什么后果？
答：我们只能使用模糊搜索，来进行匹配，会导致很多数据匹配不到。所以，我们必须使用全文检索。

二、Lucene实现全文检索的流程


image.png
全文检索的流程分为两大部分：索引流程、搜索流程。
索引流程：采集数据--->构建文档对象--->创建索引(将文档写入索引库)。
搜索流程：创建查询--->执行搜索--->渲染搜索结果。

三、配置步骤说明

（1）搭建环境（先下载Lucene）
1、下载Lucene
Lucene是开发全文检索功能的工具包，使用时从官方网站下载，并解压。
官方网站：http://lucene.apache.org/
下载地址：http://archive.apache.org/dist/lucene/java/
2、创建项目，导入包
mysql5.1驱动包：mysql-connector-java-5.1.7-bin.jar
核心包：lucene-core-4.10.3.jar
分析器通用包：lucene-analyzers-common-4.10.3.jar
查询解析器包：lucene-queryparser-4.10.3.jar

（2）创建索引库
1.采集数据
2.将数据转换成Lucene文档
3.将文档写入索引库，创建索引
（具体代码不在此写出）

（3）搜索索引库
（具体代码不在此写出）

四、分词

（1） 重要性

分词是全文检索的核心。
所谓的分词，就是将一段文本，根据一定的规则，拆分成一个一个词。
Lucene是根据分析器实现分词的。针对不同的语言提供了不同的分析器。并且提供了一个通用的标准分析器StandardAnalyzer

（2）Lucene分词的过程

分词的时候，是以域为单位的。不同的域，相互独立。
同一个域中，拆分出来相同的词，视为同一个词（Term）
不同的域中，拆分出来相同的词，不是同一个词。
其中，Term是Lucene最小的语汇单元，不可再细分。
分词的时候经历了一系列的过滤器。如大小写转换、去除停用词等。

（3）分词后索引库结构
索引库中有两个区域：索引区、文档区。
文档区存放的是文档。Lucene给每一个文档自动加上一个文档编号docID。
索引区存放的是索引。注意：
索引是以域为单位的，不同的域，彼此相互独立。
索引是根据分词规则创建出来的，根据索引就能找到对应的文档。

五、Field域
（1）三大属性

1.是否分词（tokenized）

只有设置了分词属性为true，lucene才会对这个域进行分词处理。
在实际的开发中，有一些字段是不需要分词的，比如商品id，商品图片等。
而有一些字段是必须分词的，比如商品名称，描述信息等。

是否索引（indexed）
只有设置了索引属性为true，lucene才为这个域的Term词创建索引。
在实际的开发中，有一些字段是不需要创建索引的，比如商品的图片等。我们只需要对参与搜索的字段做索引处理。

3.是否存储（stored）

只有设置了存储属性为true，在查找的时候，才能从文档中获取这个域的值。
在实际开发中，有一些字段是不需要存储的。比如：商品的描述信息。
因为商品描述信息，通常都是大文本数据，读的时候会造成巨大的IO开销。而描述信息是不需要经常查询的字段，这样的话就白白浪费了cpu的资源了。
因此，像这种不需要经常查询，又是大文本的字段，通常不会存储到索引库。

（2）特点

三大属性彼此独立。
通常分词是为了创建索引。

作者：kelaody
链接：https://www.jianshu.com/p/280ac3fdf007
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
